/**
 * @example{lineno} C++/CustomCppProblem/main.cpp
 * This example shows how to define optimization problems using ordinary C++
 * functions.  
 *
 * It solves a simple quadratic program of the form:
 * @f[ \begin{aligned}
 * & \underset{x}{\text{minimize}} && \tfrac12 \tp x Q x \\ 
 * & \text{subject to} && Ax \le b \\ 
 * \end{aligned} @f]
 *
 * ## Problem specification
 *
 * The quadratic program described above can be formulated as a general NLP of
 * the following form:
 *
 * @f[ \begin{aligned}
 * & \underset{x}{\text{minimize}} && f(x) \\ 
 * & \text{subject to} && x \in C \subseteq \R^n \\ 
 * &&& g(x) \in D \subseteq \R^m. \\ 
 * \end{aligned} @f]
 *
 * The problem is specified by creating a class (`Problem`) that inherits from
 * alpaqa's @ref alpaqa::BoxConstrProblem class. It defines the problem-specific
 * functions for the evaluation of the cost function @f$ f(x) = \tfrac12 \tp xQx @f$
 * (@ref alpaqa::TypeErasedProblem::eval_f "eval_f") and its gradient
 * @f$ \nabla f(x) = Qx @f$ (@ref alpaqa::TypeErasedProblem::eval_grad_f "eval_grad_f"),
 * as well as the constraint function @f$ g(x) = Ax @f$
 * (@ref alpaqa::TypeErasedProblem::eval_g "eval_g") and the function that
 * evaluates the product of the gradient of the constraints and a given vector
 * @f$ y @f$, @f$ \nabla g(x)\,y = \tp A y @f$
 * (@ref alpaqa::TypeErasedProblem::eval_grad_g_prod "eval_grad_g_prod").
 *
 * If you have more efficient ways to combine evaluations of these functions and
 * gradients, you can specify them as well, see the
 * @ref page-problem-formulations page and the @ref alpaqa::TypeErasedProblem
 * documentation for the full list of supported functions.
 *
 * The @ref alpaqa::BoxConstrProblem class exposes the two constraint sets,
 * @f$ x \in C @f$ and @f$ g(x) \in D @f$, and provides the projection functions
 * (@ref alpaqa::TypeErasedProblem::eval_prox_grad_step "eval_prox_grad_step", 
 * @ref alpaqa::TypeErasedProblem::eval_proj_diff_g "eval_proj_diff_g" and
 * @ref alpaqa::TypeErasedProblem::eval_proj_multipliers "eval_proj_multipliers")
 * for you.
 * The @ref alpaqa::BoxConstrProblem constructor accepts the number of variables
 * @f$ n = 2 @f$ and the number of constraints @f$ m = 1 @f$ as arguments.
 *
 * @note Alpaqa uses [structural typing](https://en.wikipedia.org/wiki/Structural_type_system)
 *       for problem definitions. This means that you just have to provide the
 *       supported functions with the correct names and arguments, and the
 *       library will pick them up automatically, you don't have to inherit from
 *       any abstract interfaces or override any virtual functions. See
 *       @ref page-problem-formulations for more information.
 *
 * @see If you haven't already, be sure to go through the
 *      @ref page-problem-formulations page.
 *
 * ## Solver selection
 *
 * The solver consists of three layers:
 *
 *   1. The outer augmented Lagrangian solver (@ref alpaqa::ALMSolver) that
 *      handles the general constraints @f$ g(x) \in D @f$;
 *   2. The inner PANOC solver (@ref alpaqa::PANOCSolver) that is used to solve
 *      the ALM subproblems;
 *   3. The L-BFGS direction (@ref alpaqa::LBFGSDirection) that provides fast
 *      Newton-type directions to speed up PANOC.
 *
 * You can try out different inner solvers (@ref grp_InnerSolvers) and
 * direction providers (@ref grp_DirectionProviders), you can even write your
 * own.
 *
 * ## Solver configuration
 *
 * Each solver and direction class has a set of parameters, which are
 * collected in a struct. Tuning these parameters can often significantly
 * improve solver performance. You can also use them to limit the run time or
 * the number of iterations, and to enable verbose output from the solvers.
 *
 * ## Solver invocation
 *
 * The solver is invoked by calling the solver object with an instance of the
 * problem and an initial guess for the Lagrange multipliers and the decision
 * variables. The solver will overwrite these guesses with the (approximate)
 * solution, and returns a struct containing solver statistics, the most
 * important of which is the @ref alpaqa::ALMSolver::Stats::status "status",
 * which reports whether convergence to the desired tolerance was achieved.
 */

/**
 * @example{lineno} C++/SimpleUnconstrProblem/main.cpp
 * This example shows how to define a simple unconstrained optimization problem
 * using ordinary C++ functions.  
 *
 * The problem is the unconstrained minimization of the
 * [Rosenbrock function](https://en.wikipedia.org/wiki/Rosenbrock_function):
 * @f[ \begin{aligned}
 * & \underset{x, y}{\text{minimize}} && (a - x)^2 + b (y - x^2)^2 \\
 * \end{aligned} @f]
 *
 * Only the inner solver (@ref grp_InnerSolvers) is used, without an augmented
 * Lagrangian outer solver.
 */

/**
 * @example{lineno} C++/FortranProblem/main.cpp
 * This example shows how to define optimization problems using Fortran 
 * routines.  
 *
 * It solves a simple quadratic program of the form:
 * @f[ \begin{aligned}
 * & \underset{x}{\text{minimize}} && \tfrac12 \tp x Q x \\ 
 * & \text{subject to} && Ax \le b \\ 
 * \end{aligned} @f]
 *
 * # Problem definition in Fortran
 * @include C++/FortranProblem/problem.f90
 * # Problem solution using alpaqa
 */

/**
 * @example{lineno} C++/DLProblem/main.cpp
 * This example shows how to load optimization problems from an external library
 * using `dlopen`.  
 *
 * It solves a simple quadratic program of the form:
 * @f[ \begin{aligned}
 * & \underset{x}{\text{minimize}} && \tfrac12 \tp x Q x \\ 
 * & \text{subject to} && Ax \le b \\ 
 * \end{aligned} @f]
 *
 * # Problem definition in C
 * @include C++/DLProblem/problem.c
 * # Problem solution using alpaqa
 */

/** 
 * @example{lineno} C++/CasADi/Rosenbrock/main.cpp
 * This example shows how to generate a problem using CasADi and how to load
 * and solve it using alpaqa.  
 *
 * # Problem generation using CasADi
 * @include CasADi/Rosenbrock/codegen-rosenbrock.py
 * # Problem solution using alpaqa
 */

/**
 * @example{lineno} C++/CustomControlCppProblem/main.cpp
 * Bare-bones example demonstrating how to define optimal control problems for
 * @ref alpaqa::PANOCOCPSolver.
 */

/**
 * @example Python/simple_optimization/getting-started.py
 * This is a minimal example of an optimization problem that can be built and
 * solved using the `alpaqa` Python interface.  
 */

/**
 * @example Python/simple_optimization/rosenbrock.py
 * This is a minimal example of an optimization problem that can be built and
 * solved using the `alpaqa` Python interface. It includes visualization of the
 * iterates.  
 */

/**
 * @example problems/sparse-logistic-regression.cpp
 * This is an example that builds a problem in C++ that can be loaded
 * dynamically by the alpaqa solvers.
 * The problem is a simple sparse logistic regression task.
 *
 * All problem functions are implemented as member functions of the `Problem`
 * class. This class also contains a member `funcs` of type
 * @ref alpaqa_problem_functions_t, which is used to expose those functions to
 * the solvers. The provided problem functions are added to this `funcs` struct
 * by the `Problem` constructor. To adapt the member functions to ordinary
 * function pointers, the @ref alpaqa::member_caller function is used.  
 * The constructor also loads the actual classification data from the given
 * CSV file.
 *
 * The main entry point is the `register_alpaqa_problem` function at the bottom.
 * It is the only function that is exported from the shared module, and it
 * is called by the @ref alpaqa::dl::DLProblem class when loading the problem
 * for the solvers.  
 * Its purpose is to create a problem instance, and return a pointer to it,
 * as well as additional information such as how to clean up the created
 * problem, and a pointer to the provided functions (the `funcs` member from
 * earlier).
 *
 * The entry point also accepts an argument with type-erased user data. You can
 * use this to pass any additional data to the problem constructor, such as
 * problem parameters. When using the `alpaqa-driver` program, the type of this
 * user data is always `std::any *`. Inside of the `std::any`, there is a span
 * of string views containing the problem-specific command line options.  
 * In this example, the `datafile` and `λ_factor` options are supported.
 * The former selects the CSV file to load the data from, the latter controls
 * the regularization parameter.
 *
 * To run this example, first build the `alpaqa-driver` program, and then build
 * the `sparse-logistic-regression` module. The regression data is generated by
 * executing the `generate-data.py` script (requires the `scikit-learn`
 * package), it outputs a CSV file that is loaded in the `load_data` function
 * defined below.  
 * Finally, execute the driver with the appropriate arguments as shown below.
 * ```sh
 * export CFLAGS="-march=native"; export CXXFLAGS="-march=native"; export FFLAGS="-march=native"
 * cmake -Bbuild -S. -G "Ninja Multi-Config" -D CMAKE_POSITION_INDEPENDENT_CODE=On
 * cmake --build build -j --config RelWithDebInfo -t driver
 * cmake --build build -j --config RelWithDebInfo -t sparse-logistic-regression
 * python3 -m pip install -U scikit-learn
 * python3 examples/problems/generate-data.py
 * ./build/src/RelWithDebInfo/alpaqa-driver \
 *     build/examples/problems/RelWithDebInfo/sparse-logistic-regression.so \
 *     problem.datafile=breast_cancer.csv \
 *     problem.λ_factor=1e-5 \
 *     sol=output/ \
 *     method=panoc.lbfgs
 * ```
 * The solution is written to a CSV file in the `output` directory.
 *
 * Run `./build/src/RelWithDebInfo/alpaqa-driver` without arguments for usage
 * and argument information.
 */
/**
 * @example{lineno} C++/Advanced/lasso-fbs.cpp
 *
 * Applies forward-backward splitting (FBS) to a lasso problem. Demonstrates
 * the use of the @ref alpaqa::prox_step function.
 */
